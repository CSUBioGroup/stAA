# stAA
stAA: Adversarial graph autoencoder for spatial clustering task of spatially resolved transcriptomics

## Overview
It mainly contains three steps. In Step 1, a variational graph autoencoder (VGAE) produces the latent embedding and reconstructs the spatial graph. Then, the Wasserstein distance in the adversarial learning framework is learned based on the latent and target distributions. The encoder is further updated through the learnt adversarial framework and generator.  Furthermore, a classifier is built to make full use of the gene expression data. This classifier allows the latent embedding to capture global graph information derived from the pre-clustering group labels. Finally, the latent embedding is regenerated by the updated encoder of the adversarial variational architecture. Based on this embedding, the spatial domains are detected by the downstream clustering algorithms


## Installation

Clone this repository. The stAA has been implemented in Python3.8.16 and Pytorch 1.13.1.

```
git clone https://github.com/CSUBioGroup/stAA.git
cd stAA/
```


## Datasets
All datasets used in our paper can be found in:

* DPLFC: 
The primary source: https://github.com/LieberInstitute/spatialLIBD; 
The processed version: https://www.nature.com/articles/s41593-020-00787-0.

* Human breast cancer: 
The primary source: https://www.10xgenomics.com/resources/datasets/human-breast-cancer-block-a-section-1-1-standard-1-1-0; 
The processed version: https://github.com/JinmiaoChenLab/SEDR_analyses/.

* Slide-seqV2 mouse olfactory bulb:  
The primary source: https://singlecell.broadinstitute.org/single_cell/study/SCP815/highly-sensitive-spatial-transcriptomics-at-near-cellular-resolution-with-slide-seqv2#study-summary; 
The processed version: https://stagate.readthedocs.io/en/latest/T3_Slide-seqV2.html.

* Slide-seqV2 mouse hippocampus: 
The primary source: https://singlecell.broadinstitute.org/single_cell/study/SCP354/slide-seq-study; 
The processed version: https://squidpy.readthedocs.io/en/stable/api/squidpy.datasets.slideseqv2.html.

* MOSTA database: 
The primary source: https://db.cngb.org/stomics/mosta/; 
The processed version: https://db.cngb.org/stomics/mosta/download/.



## Usage
We provided some demos to demonstrate usage of stAA. 

Hyperparameter of graph mode
| DLPFC | Human breast cancer | Mouse olfactory bulb | Mouse hippocampus | MOSTA | STARmap |
|-------|---------------------|----------------------|-------------------|-------|---------|
| 150   | 300                 | 50                   | 40                | knn   | 400     |


```Python
## DLPFC
# load data
adata = sc.read('./filtered_feature_bc_matrix.h5ad')
adata.var_names_make_unique()
# add ground_truth
df_meta = pd.read_table('/151676_truth.txt', sep='\t', header=None, index_col=0)
df_meta.columns = ['groud_truth']
adata.obs['ground_truth'] = df_meta.loc[adata.obs_names, 'groud_truth'].values
# train model and cluster
# if the data_save_path is not None, the embeddings generated by stAA are saved as 'embedding.npy' and the cluster labels are stored in 'types.txt'.
res = run_stAA(adata, n_clusters=7, 
               cluster_method="mclust", refine=True, 
               graph_mode=150, eval=True,
               data_save_path="./")
print(res["ari"])
```


```Python
## mouse hippocampus
# load data
import squidpy as sq
adata = sq.datasets.slideseqv2()
adata.var_names_make_unique()
# train model and cluster
res = run_stAA(adata, n_clusters=10, 
               cluster_method="mclust", refine=False, 
               graph_mode=40, eval=False,
               data_save_path="./")
print(res["embedding"])
print(res["pred_label"])
```

```Python
## mouse olfactory bulb
# load data
adata = sc.read('./filtered_feature_bc_matrix.h5ad')
adata.var_names_make_unique()
# train model and cluster
res = run_stAA(adata, n_clusters=0.5, 
               cluster_method="louvain", refine=False, 
               graph_mode=50, eval=False,
               data_save_path="./")
```
